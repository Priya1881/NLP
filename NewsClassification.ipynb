{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewsClassification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1D_u-e_q-McQU-iQ_gXVbTHDKI-AErk6M",
      "authorship_tag": "ABX9TyNP7hmmbeECrjfMxSkcXOhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya1881/NLP/blob/main/NewsClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDU4Fd1V8OJh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhakMxbc7l6E"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijb9IZxc7t19"
      },
      "source": [
        "def read_files(path):\n",
        "    file_contents=[]\n",
        "    filenames=os.listdir(path)\n",
        "    for i in range(len(filenames)):\n",
        "        with open(path + filenames[i],encoding=\"ISO-8859-1\") as f:\n",
        "            file_contents.append(f.read())\n",
        "    return file_contents\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqejYAuqI-bN"
      },
      "source": [
        "class_0 = read_files('/content/drive/MyDrive/comp.graphics/')\n",
        "class_1 = read_files('/content/drive/MyDrive/rec.motorcycles/')\n",
        "class_2 = read_files('/content/drive/MyDrive/sci.med/')\n",
        "class_3 = read_files('/content/drive/MyDrive/talk.politics.misc/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgUnlwqSI-nG"
      },
      "source": [
        "all_texts=np.append(class_0,class_1)\n",
        "all_texts=np.append(all_texts,class_2)\n",
        "all_texts= np.append(all_texts,class_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7cs0B_qXBwa"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDMye_VbI-qc"
      },
      "source": [
        "stop_words= set(stopwords.words('english'))\n",
        "\n",
        "def clean(text):\n",
        "    #lowering letters\n",
        "    text = text.lower()\n",
        "    #removing html tags\n",
        "    text = re.sub('<[^>]*>',' ',text)\n",
        "    # removing emails\n",
        "    text = re.sub('\\S*@\\S*\\s?',' ',text)\n",
        "    # removing urls\n",
        "    text = re.sub('https?://[A-Za-z0-9]',' ',text)\n",
        "    #removing numbers\n",
        "    text = re.sub('[^A-Za-z]',' ',text)\n",
        "    \n",
        "    word_tokens=word_tokenize(text)\n",
        "    filtered_sentence=[]\n",
        "    for word_token in word_tokens:\n",
        "        if word_token not in stop_words and len(word_token) > 2:\n",
        "            filtered_sentence.append(word_token)\n",
        "    #joining words\n",
        "    text=' '.join(filtered_sentence)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCxUY5NcXQOx"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHYwyxoNI-vJ"
      },
      "source": [
        "all_cleaned_texts = np.array([clean(text) for text in all_texts])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf_uG__2I-yZ"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_cleaned_texts)\n",
        "all_encoded_texts=tokenizer.texts_to_sequences(all_cleaned_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhTrztrYJRZe"
      },
      "source": [
        "all_encoded_texts = np.array(all_encoded_texts)\n",
        "len(all_encoded_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_O92PXMJRcb"
      },
      "source": [
        "all_encoded_texts = sequence.pad_sequences(all_encoded_texts, maxlen=500)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdLYfsNtJRfM"
      },
      "source": [
        "labels_0=np.array([0]*len(class_0))\n",
        "labels_1=np.array([1]*len(class_1))\n",
        "labels_2=np.array([2]*len(class_2))\n",
        "labels_3=np.array([3]*len(class_3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drKjftniYALE"
      },
      "source": [
        "all_labels = np.append(labels_0,labels_1)\n",
        "all_labels = np.append(all_labels,labels_2)\n",
        "all_labels = np.append(all_labels,labels_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3meNFqvJdft"
      },
      "source": [
        "all_labels=all_labels[:,np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Iw75FuSJdqj"
      },
      "source": [
        "one_hot_encoder=OneHotEncoder(sparse=False)\n",
        "all_labels=one_hot_encoder.fit_transform(all_labels)\n",
        "print(all_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CGuCdYPJduS"
      },
      "source": [
        "Xtrain,Xtest,ytrain,ytest=train_test_split(all_encoded_texts,all_labels,test_size=0.2,random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUkS9e1kJlIT"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=34869,output_dim=32,input_length=500))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(4,activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG4YESD2JlLq"
      },
      "source": [
        "history=model.fit(Xtrain,ytrain,epochs=12,batch_size=64,validation_data=(Xtest,ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6ZfhOKIYxlD"
      },
      "source": [
        "predictions = model.predict(Xtest)\n",
        "predictions = one_hot_encoder.inverse_transform(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHBEMj_6Y8Sx"
      },
      "source": [
        "ytest_evaluate = np.argmax(ytest,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mwchQ7yZQCy"
      },
      "source": [
        "cm=confusion_matrix(ytest_evaluate,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRCOTNxUZePD"
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok4xPzcyZggH"
      },
      "source": [
        "string='''Yes, very serious.  I claim that I can substantiate my statement that\n",
        "  Rudman says he doesn't believe Perot was investigating him.  You claim\n",
        "Perot was investigating him.  If you will state that you were in error\n",
        "on this point, provided I produce the source, I'll go dig it up.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx2uxPNBZs7y"
      },
      "source": [
        "cleaned_string = clean(string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdq25EHWa3u_"
      },
      "source": [
        "cleaned_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANQE4l73ZwWt"
      },
      "source": [
        "encoded_string = tokenizer.texts_to_sequences([cleaned_string])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4We4ltuZ83r"
      },
      "source": [
        "encoded_string = sequence.pad_sequences(encoded_string,maxlen=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiadtBChaIJ4"
      },
      "source": [
        "string_predicted = model.predict(encoded_string)\n",
        "np.argmax(string_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}